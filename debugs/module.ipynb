{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 512])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_parameters())['fc.weight'].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 512])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[-2].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicBlock(\n",
       "  (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (downsample): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['layer4']._modules['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Activation Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def preprocess(image, image_size=(224, 224), device='cpu'):\n",
    "    sample = cv2.resize(image, dsize=image_size)\n",
    "    sample = torch.from_numpy(sample).to(device).to(torch.float)\n",
    "    sample = sample.unsqueeze(dim=0).permute(0, 3, 1, 2)\n",
    "    sample = (sample - sample.mean()) / sample.std()\n",
    "\n",
    "    return image, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = 'weights/hole_detection/transformer_resnet18/2103191437/best_model_83_loss=-0.1259.pt'\n",
    "device = 'cpu'\n",
    "num_classes = 2\n",
    "\n",
    "model = TransformerResnet18(num_classes)\n",
    "model.load_state_dict(torch.load(weight_path, map_location='cpu'))\n",
    "model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_map(model, sample, last_layer_name='self_attention'):\n",
    "    # without transformer\n",
    "#     feature_map = model._modules[last_layer_name](sample)  # [1, 512, 7, 7]\n",
    "    \n",
    "    # with transformer\n",
    "    feature_map = model._modules['resnet18_conv'](sample)\n",
    "    B, C, H, W = feature_map.shape\n",
    "    feature_map = feature_map.reshape(B, C, H * W).permute(2, 0, 1).contiguous()\n",
    "    feature_map = model._modules[last_layer_name](feature_map)  # [49, 1, 512]\n",
    "    feature_map = feature_map.permute(1, 2, 0).contiguous().reshape(B, C, H, W)  # [1, 512, 7, 7]\n",
    "\n",
    "    return feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../ID_CARD/hole_classification/dataset_update/test/hole/CMQD_A/2_05003827_GTTT-page0.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "image, sample = preprocess(image)\n",
    "print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "feature_map = get_feature_map(model, sample)\n",
    "print(feature_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512])\n"
     ]
    }
   ],
   "source": [
    "# get weight of fully connected layers\n",
    "fc_classes_weights = list(model.parameters())[-2]\n",
    "print(fc_classes_weights.shape)  # [n_classes, feature_map_channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hole 0.9997307658195496\n"
     ]
    }
   ],
   "source": [
    "# class prediction\n",
    "with torch.no_grad():\n",
    "    preds = model(sample)\n",
    "\n",
    "pred = preds.softmax(dim=1).squeeze(dim=0)\n",
    "class_idx = pred.argmax().item()\n",
    "class_name = classes[class_idx]\n",
    "class_score = pred[class_idx].item()\n",
    "print(class_name, class_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weight of predicted class\n",
    "fc_class_weights = fc_classes_weights[class_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 7])\n"
     ]
    }
   ],
   "source": [
    "B, C, H, W = feature_map.shape\n",
    "feature_map = feature_map.reshape(C, H * W)\n",
    "CAM = torch.matmul(fc_class_weights, feature_map)\n",
    "CAM = CAM.reshape(H, W)\n",
    "print(CAM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[235 197 204 221 238 225 243]\n",
      " [240 175 195 205 230 210 233]\n",
      " [232 202 216 235 246 255 253]\n",
      " [170  77 121 171 241 236 248]\n",
      " [123  55  79 151 213 200 225]\n",
      " [ 81   0   8  83 175 171 216]\n",
      " [109  42  50 132 185 179 207]]\n"
     ]
    }
   ],
   "source": [
    "CAM = (CAM - CAM.min()) / (CAM.max() - CAM.min())\n",
    "CAM = (CAM * 255).to(torch.uint8).cpu().detach().numpy()\n",
    "print(CAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(492, 733)\n"
     ]
    }
   ],
   "source": [
    "CAM = cv2.resize(CAM, dsize=(image.shape[1], image.shape[0]))\n",
    "print(CAM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAM_heatmap = cv2.applyColorMap(CAM, cv2.COLORMAP_JET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = (CAM_heatmap * 0.5 + image * 0.5).astype(np.uint8)\n",
    "cv2.imshow('heatmap', heatmap)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

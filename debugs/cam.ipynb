{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TransformerResnet18(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=False):\n",
    "        super(TransformerResnet18, self).__init__()\n",
    "        resnet18_model = torchvision.models.resnet18(pretrained=pretrained)\n",
    "        self.resnet18_conv = nn.Sequential(*list(resnet18_model.children())[:-2])\n",
    "        self.self_attention = nn.TransformerEncoderLayer(d_model=resnet18_model.fc.in_features, nhead=8)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.linear = nn.Linear(in_features=resnet18_model.fc.in_features, out_features=num_classes, bias=True)\n",
    "        self.linear.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.resnet18_conv(x)\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.reshape(B, C, H * W).permute(2, 0, 1).contiguous()\n",
    "        x = self.self_attention(x)\n",
    "        x = x.permute(1, 2, 0).contiguous().reshape(B, C, H, W)\n",
    "        x = self.avg_pool(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Resnet18(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=False):\n",
    "        super(Resnet18, self).__init__()\n",
    "        resnet18_model = torchvision.models.resnet18(pretrained=pretrained)\n",
    "        self.resnet18_conv = nn.Sequential(*list(resnet18_model.children())[:-2])\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.linear = nn.Linear(in_features=resnet18_model.fc.in_features, out_features=num_classes, bias=True)\n",
    "        self.linear.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.resnet18_conv(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.linear(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_instance(config):\n",
    "    module = config['module']\n",
    "    class_ = config['class']\n",
    "    config_kwargs = config.get(class_, {})\n",
    "    for key, value in config_kwargs.items():\n",
    "        if isinstance(value, str):\n",
    "            config_kwargs[key] = eval(value)\n",
    "    if module:\n",
    "        return getattr(import_module(module), class_)(**config_kwargs)\n",
    "    else:\n",
    "        return eval(class_)(**config_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "resnet18_config = {\n",
    "    'module': None,\n",
    "    'class': 'CAM',\n",
    "    'CAM': {\n",
    "        'arch_config': {'module': None, 'class': 'Resnet18', 'Resnet18': {'num_classes': 2,}},\n",
    "        'classes': ['hole', 'none'],\n",
    "        'image_size': (224, 224),\n",
    "        'weight_path': \"'weights/hole_detection/resnet18/2103191429/best_model_94_loss=-0.1392.pt'\",\n",
    "        'device': \"'cpu'\",\n",
    "    }\n",
    "}\n",
    "\n",
    "trasformer_resnet18_config = deepcopy(resnet18_config)\n",
    "trasformer_resnet18_config['CAM']['arch_config'] = {'module': None, 'class': 'TransformerResnet18', 'TransformerResnet18': {'num_classes': 2}}\n",
    "trasformer_resnet18_config['CAM']['weight_path'] = \"'weights/hole_detection/transformer_resnet18/2103191437/best_model_83_loss=-0.1259.pt'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CAM(nn.Module):\n",
    "    def __init__(self, arch_config, classes, weight_path, image_size, device):\n",
    "        super(CAM, self).__init__()\n",
    "        self.device = device\n",
    "        self.model = create_instance(arch_config)\n",
    "        self.model.load_state_dict(torch.load(weight_path, map_location='cpu'))\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        self.classes = classes\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.activation = None\n",
    "\n",
    "    def _register_forward_hook(self, target_layer):\n",
    "        assert target_layer in list(self.model._modules.keys()), 'target_layer must be in list of modules of model'\n",
    "\n",
    "        def hook_feature(module, input, output):\n",
    "            self.activation = output.data\n",
    "\n",
    "        def hook_attention_feature(module, input, output):\n",
    "            HW, B, C = output.shape\n",
    "            H, W = int(math.sqrt(HW)), int(math.sqrt(HW))\n",
    "            self.activation = output.reshape(H, H, B, C).permute(2, 3, 0, 1).contiguous()\n",
    "\n",
    "        if target_layer == 'self_attention':\n",
    "            self.model._modules.get(target_layer).register_forward_hook(hook_attention_feature)\n",
    "        else:\n",
    "            self.model._modules.get(target_layer).register_forward_hook(hook_feature)\n",
    "\n",
    "    def _get_softmax_weights(self, linear_layer=None):\n",
    "        if linear_layer:\n",
    "            assert linear_layer in list(self.model._modules.keys()), 'classifier_layer must be in list of modules of model'\n",
    "            softmax_weights = dict(self.model.named_parameters())[linear_layer].data\n",
    "        else:\n",
    "            softmax_weights = list(self.model.parameters())[-2].data\n",
    "        return softmax_weights\n",
    "\n",
    "    def preprocess(self, image):\n",
    "        sample = cv2.resize(image, dsize=self.image_size)\n",
    "        sample = torch.from_numpy(sample).to(self.device).to(torch.float)\n",
    "        sample = sample.unsqueeze(dim=0).permute(0, 3, 1, 2)\n",
    "        sample = (sample - sample.mean()) / sample.std()\n",
    "        return sample\n",
    "\n",
    "    def process(self, sample):\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(sample)\n",
    "        return preds\n",
    "\n",
    "    def postprocess(self, preds):\n",
    "        pred = preds.softmax(dim=1).squeeze(dim=0)\n",
    "        class_name = self.classes[pred.argmax().item()]\n",
    "        class_score = pred[pred.argmax()].item()\n",
    "        return class_name, class_score\n",
    "\n",
    "    def class_activation_map(self, sample, map_size, target_layer, linear_layer=None):\n",
    "        self._register_forward_hook(target_layer=target_layer)\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(sample)\n",
    "\n",
    "        class_idx = preds.softmax(dim=1).squeeze(dim=0).argmax().item()\n",
    "        softmax_weights = self._get_softmax_weights(linear_layer=linear_layer)\n",
    "        softmax_weight = softmax_weights[class_idx, :]\n",
    "        activation_map = self.activation\n",
    "        \n",
    "        _, C, H, W = activation_map.shape\n",
    "        activation_map = activation_map.reshape(C, H * W)\n",
    "        saliency_map = torch.matmul(softmax_weight, activation_map)\n",
    "        saliency_map = saliency_map.reshape(H, W)\n",
    "        saliency_map = F.relu(saliency_map)\n",
    "\n",
    "        saliency_map_min, saliency_map_max = saliency_map.min(), saliency_map.max()\n",
    "        saliency_map = (saliency_map - saliency_map_min).div(saliency_map_max - saliency_map_min).data\n",
    "\n",
    "        saliency_map = (saliency_map * 255).to(torch.uint8).cpu().detach().numpy()\n",
    "        saliency_map = cv2.resize(saliency_map, dsize=map_size)\n",
    "        saliency_map = cv2.applyColorMap(saliency_map, cv2.COLORMAP_JET)\n",
    "\n",
    "        return saliency_map\n",
    "\n",
    "    def forward(self, image, target_layer='resnet18_conv', linear_layer=None):\n",
    "        sample = self.preprocess(image)\n",
    "        preds = self.process(sample)\n",
    "        class_name, class_score = self.postprocess(preds)\n",
    "        heatmap = self.class_activation_map(sample, image.shape[1::-1], target_layer, linear_layer)\n",
    "        heatmap = (heatmap * 0.5 + image * 0.5).astype(np.uint8)\n",
    "        return class_name, class_score, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_detector = create_instance(resnet18_config)\n",
    "transformer_resnet18_detector = create_instance(trasformer_resnet18_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../ID_CARD/hole_classification/dataset_update/test/hole/CMQD_A/2_001136846_GTTT-page2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(resnet18_detector(image))\n",
    "# print(transformer_resnet18_detector(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Feature Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "922\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "image_paths = list(Path('../../ID_CARD/hole_classification/dataset_update/test/hole/').glob('**/*.*'))\n",
    "random.shuffle(image_paths)\n",
    "print(len(image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../ID_CARD/hole_classification/dataset_update/test/hole/CMQD_D/2_15040569_GTTT-page0.jpg\n",
      "****************************************\n",
      "resnet18_conv torch.Size([1, 512, 7, 7])\n",
      "none 0.9639642834663391\n",
      "resnet18_conv torch.Size([1, 512, 7, 7])\n",
      "none 0.9714662432670593\n",
      "self_attention torch.Size([1, 512, 7, 7])\n",
      "none 0.9714662432670593\n",
      "../../ID_CARD/hole_classification/dataset_update/test/hole/CMQD_A_BACK/2_41A123052972_GTTT-page1.jpg\n",
      "****************************************\n",
      "resnet18_conv torch.Size([1, 512, 7, 7])\n",
      "hole 0.9997718930244446\n",
      "resnet18_conv torch.Size([1, 512, 7, 7])\n",
      "hole 0.9997168183326721\n",
      "self_attention torch.Size([1, 512, 7, 7])\n",
      "hole 0.9997168183326721\n"
     ]
    }
   ],
   "source": [
    "# image = cv2.imread('../../ID_CARD/hole_classification/dataset_update/test/hole/CMQD_A/2_08029910_GTTT-page0.jpg')\n",
    "max_height = 500\n",
    "\n",
    "for idx, image_path in enumerate(image_paths):\n",
    "    if idx == 10:\n",
    "        break\n",
    "\n",
    "    print(image_path)\n",
    "    print('**' * 20)\n",
    "    image = cv2.imread(str(image_path))\n",
    "    \n",
    "    class_name, class_score, heat_map = resnet18_detector(image, target_layer='resnet18_conv')\n",
    "    print(class_name, class_score)\n",
    "    cv2.imshow('resnet18_conv', heat_map)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    class_name, class_score, heat_map = transformer_resnet18_detector(image, target_layer='resnet18_conv')   \n",
    "    print(class_name, class_score)\n",
    "    cv2.imshow('transformer_resnet18_conv', heat_map)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    class_name, class_score, heat_map = transformer_resnet18_detector(image, target_layer='self_attention')\n",
    "    print(class_name, class_score)\n",
    "    cv2.imshow('self_attention', heat_map)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Activation Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def preprocess(image, image_size=(224, 224), device='cpu'):\n",
    "    sample = cv2.resize(image, dsize=image_size)\n",
    "    sample = torch.from_numpy(sample).to(device).to(torch.float)\n",
    "    sample = sample.unsqueeze(dim=0).permute(0, 3, 1, 2)\n",
    "    sample = (sample - sample.mean()) / sample.std()\n",
    "\n",
    "    return image, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = 'weights/hole_detection/transformer_resnet18/2103191437/best_model_83_loss=-0.1259.pt'\n",
    "device = 'cpu'\n",
    "num_classes = 2\n",
    "\n",
    "model = TransformerResnet18(num_classes)\n",
    "model.load_state_dict(torch.load(weight_path, map_location='cpu'))\n",
    "model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_map(model, sample, last_layer_name='self_attention'):\n",
    "    # without transformer\n",
    "#     feature_map = model._modules[last_layer_name](sample)  # [1, 512, 7, 7]\n",
    "    \n",
    "    # with transformer\n",
    "    feature_map = model._modules['resnet18_conv'](sample)\n",
    "    B, C, H, W = feature_map.shape\n",
    "    feature_map = feature_map.reshape(B, C, H * W).permute(2, 0, 1).contiguous()\n",
    "    feature_map = model._modules[last_layer_name](feature_map)  # [49, 1, 512]\n",
    "    feature_map = feature_map.permute(1, 2, 0).contiguous().reshape(B, C, H, W)  # [1, 512, 7, 7]\n",
    "\n",
    "    return feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../../ID_CARD/hole_classification/dataset_update/test/hole/CMQD_A/2_05003827_GTTT-page0.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "image, sample = preprocess(image)\n",
    "print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "feature_map = get_feature_map(model, sample)\n",
    "print(feature_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512])\n"
     ]
    }
   ],
   "source": [
    "# get weight of fully connected layers\n",
    "fc_classes_weights = list(model.parameters())[-2]\n",
    "print(fc_classes_weights.shape)  # [n_classes, feature_map_channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hole 0.9997307658195496\n"
     ]
    }
   ],
   "source": [
    "# class prediction\n",
    "with torch.no_grad():\n",
    "    preds = model(sample)\n",
    "\n",
    "pred = preds.softmax(dim=1).squeeze(dim=0)\n",
    "class_idx = pred.argmax().item()\n",
    "class_name = classes[class_idx]\n",
    "class_score = pred[class_idx].item()\n",
    "print(class_name, class_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weight of predicted class\n",
    "fc_class_weights = fc_classes_weights[class_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 7])\n"
     ]
    }
   ],
   "source": [
    "B, C, H, W = feature_map.shape\n",
    "feature_map = feature_map.reshape(C, H * W)\n",
    "CAM = torch.matmul(fc_class_weights, feature_map)\n",
    "CAM = CAM.reshape(H, W)\n",
    "print(CAM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[235 197 204 221 238 225 243]\n",
      " [240 175 195 205 230 210 233]\n",
      " [232 202 216 235 246 255 253]\n",
      " [170  77 121 171 241 236 248]\n",
      " [123  55  79 151 213 200 225]\n",
      " [ 81   0   8  83 175 171 216]\n",
      " [109  42  50 132 185 179 207]]\n"
     ]
    }
   ],
   "source": [
    "CAM = (CAM - CAM.min()) / (CAM.max() - CAM.min())\n",
    "CAM = (CAM * 255).to(torch.uint8).cpu().detach().numpy()\n",
    "print(CAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(492, 733)\n"
     ]
    }
   ],
   "source": [
    "CAM = cv2.resize(CAM, dsize=(image.shape[1], image.shape[0]))\n",
    "print(CAM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAM_heatmap = cv2.applyColorMap(CAM, cv2.COLORMAP_JET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('heatmap', CAM_heatmap)\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = (CAM_heatmap * 0.5 + image * 0.5).astype(np.uint8)\n",
    "cv2.imshow('heatmap', heatmap)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
